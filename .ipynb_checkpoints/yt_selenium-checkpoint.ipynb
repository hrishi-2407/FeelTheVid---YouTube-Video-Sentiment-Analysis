{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8c565a4-382c-4c9f-a974-b4c83891dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d25e353-f866-4613-8bc3-607ed2ad555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d9a0351-d684-4355-afdb-b2acfc245965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import Word\n",
    "from slang_dict import slang_dict\n",
    "import string\n",
    "import emoji\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99e7365e-b563-4864-a006-ebb359bc3826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hrish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hrish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hrish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hrish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8d07176-cba9-47b0-b44f-97dc8827fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_youtube_comments(url):\n",
    "    \"\"\"Scrape comments from a YouTube video\"\"\"\n",
    "    comments = []\n",
    "    # chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    \n",
    "    # with webdriver.Chrome(options=chrome_options) as driver:\n",
    "    driver = webdriver.Chrome()\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    driver.get(url)\n",
    "\n",
    "    num_scrolls=5\n",
    "    for _ in range(num_scrolls):\n",
    "        wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "        time.sleep(4)\n",
    "\n",
    "    comment_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#contents\")))\n",
    "    for element in comment_elements:\n",
    "        comments.append(element.text)\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63a85afe-36ee-4def-8764-772f1e0701b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcomments\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46a17bfd-fc40-46e1-ac1c-11c882d4c8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pinned by Tech With Tim\\n@TechWithTim\\n7 months ago\\nAnother thing that gives you an unfair advantage is my software development course ;) https://techwithtim.net/dev\\n17\\nReply\\n路\\n5 replies\\n@G_a_n_d_u\\n7 months ago\\n1. Automated trading bot\\n2. Sentiment analysis \\n3. Blockchain base voting system \\n4. Online multi-player game\\n5. Computer vision related application\\nRead more\\n469\\nReply\\n7 replies\\n@mmaer\\n7 months ago\\nI developed a trading bot in 2017 and consistently include it in my resume. I agree with your point; it certainly catches the attention of hiring interviewers. They often ask, \"How did it perform? Was it successful?\" My response is always candid: the bot functioned as intended, but if it had been truly successful, I wouldn\\'t be seeking employment right now. Interestingly, this experience has been a key factor in my being hired 100% of the time.\\nRead more\\n402\\nReply\\n9 replies\\n@NoToBusinessCasual\\n7 months ago\\nThanks Tim. I just passed on your video to my daughter who is in school for computer science. I myself, even though a Comp Sci graduate, feel too old and only end up drooling at these ideas.\\n17\\nReply\\n@garrettsmith315\\n7 months ago\\nI know you\\'re a mentor to millions, but i always feels like you\\'re speaking directly about my projects!\\n21\\nReply\\n1 reply\\n@smnomad9276\\n7 months ago\\nYou\\'ve been posting some great videos lately, mainly about real life useful projects that one can do and I really appreciate that! Keep this same mindset!\\n28\\nReply\\n1 reply\\n@marcotroster8247\\n7 months ago\\nNice ideas. I\\'d suggest some low-level performance optimization as well. It shows that you know how a processor works (which makes you stand out, sadly).\\n24\\nReply\\n4 replies\\n@t_charts6851\\n4 months ago\\nGreat ideas! Do you have a video for the 5th project?\\n3\\nReply\\n@parlor3115\\n5 months ago\\nThank you. I watched this video 10 years ago, and started OpenAI. Look at it now.\\n2\\nReply\\n@thewhiteoaktree\\n7 months ago\\nI added these projects to my CV, the recruiter thought I\\'m a crypto scammer\\n24\\nReply\\n2 replies\\n@dnm9931\\n7 months ago (edited)\\nGuys how do you think is the best way to build these projects? Following a YouTube tutorial ? Or GitHub repo? Or just gathering information from different places and trying and failing? Thanks !\\n2\\nReply\\n3 replies\\n@carlossanteliz5293\\n7 months ago\\nGreat ideas and video. Thank you, Tim : )\\n2\\nReply\\n@vivienhounsounou1867\\n7 months ago\\nI didn\\'t know someone of your level could still think that there is anything new or unique. But I\\'m not surprised, our world is run and led by the blinds\\n5\\nReply\\n1 reply\\n@felixinit\\n1 month ago\\n1 Automate Trading bot\\n2 Sentiment an谩lisis\\n3 Blockchain\\n4 Multiplayer online Game\\n5 Computer vision project\\nRead more\\n1\\nReply\\n@wonjunjang3839\\n7 months ago\\nThank you for these great videos Tim!!\\n1\\nReply\\n@Shaheer-xs5os\\n7 months ago\\nDamn, all of these are really complicated for me... but thank you for these challenging projects...\\n8\\nReply\\n1 reply\\n@jwbonnett\\n7 months ago\\nTrading bots get shut down all the time and you can actually have legal issues due to building them. This is because the finacial data is usally scraped or used in a way that is prohibited by to the T&C or data that you do not own.\\n8\\nReply\\n2 replies\\n@fabiojonathanarifin1\\n7 months ago\\nI\\'ve never touch game creation (Project 4) what kind of stack and hosting that\\'d be nice for that?\\n1\\nReply\\n@hakeemgardner2161\\n7 months ago\\nWould thess be useful as an aspiring web developer?\\n1\\nReply\\n@petercooling3503\\n7 months ago\\nCan you do walkthrough of these\\n2\\nReply\\n@mkk-un9nz\\n7 months ago\\nthank you bro for sharing and by the way did you find out the cat?\\n1\\nReply\\n@user-ch1ty8vt3f\\n1 month ago\\ni guess only learning python is not enough i need to learn other techs as well for such projects you mentioned.\\nReply\\n@user-qv5jo3sl8m\\n7 months ago\\nNow 47k people have these project in their resume\\n6\\nReply\\n1 reply\\n@learner3404\\n5 months ago\\nYour Editor is awesome!\\nReply\\n@uncle-it-hk\\n7 months ago\\nI have many passwords as well, let me try the Nord pass as well, thanks again Time \\nReply\\n@VictaoBR\\n7 months ago\\nAnd today I woke up thinking of proceeding with my backtesting and day trading project to learn python\\n4\\nReply\\n@slayer1347\\n7 months ago\\nhow can i learn? any step by step books or tutorials? thanks\\nReply\\n@Elriogranade\\n7 months ago\\nWhich camera did you use for the raspberry pi?\\nReply\\n@pravachanpatra4012\\n7 months ago\\nCan you make a video on creating a neural network library from scratch?\\nReply\\n@cashpay50\\n4 months ago\\nI thought the 2nd project was to build a NordPass clone :D\\n1\\nReply\\n@silverstreetman\\n7 months ago (edited)\\nGreat content. Can you give pointers for the games. Also the computer vision if you dont mind. I am trying to teach kids building appsnand that would be of great help. Thanks in advance.\\nReply\\n路\\n1 reply\\n@matiqueedwards2269\\n3 months ago (edited)\\nOnly thing thats missing about this video is where to go to learn how to build these things , and with what languages \\nReply\\n@matasmatas7030\\n5 months ago\\nDo you have videos or courses on full-stack training? From web design, and databases to admin?\\nReply\\n路\\n1 reply\\n@Petreonvitor\\n7 months ago\\nnow this projects isnt more an unfair advantage, because you show them , but still a nice project list to put in the portfolio\\n2\\nReply\\n@dnm9931\\n7 months ago\\nHello @mmaer @TechWithTim what would be the best way of building a trading bot? Following a YouTube tutorial or just gathering information from different places in your own?\\nReply\\n@ItsMe-vo1du\\n7 months ago\\nAmazing, we need other projects ideas\\nReply\\n@ArjunSinghBhadauriya\\n7 months ago\\nThat\\'s why I subscribed To Tim\\n1\\nReply\\n@olyvarjohannes6094\\n7 months ago\\nThe sad reality is Tech is extremely overcrowded and oversaturated\\n10\\nReply\\n@sakshinarkhede3854\\n6 months ago\\nHey Tim,\\nJust discovered your channel and loving the project ideas you share! \\n\\nQuick question: how can these projects help me stand out, considering others might have done or will do them? Any tips for adding a unique twist?\\n\\n\\nAlso, when diving into these projects, I sometimes struggle to find good reference code. Any go-to resources or platforms you recommend for finding reliable code to guide my own?\\n\\nThanks a ton for the awesome content! \\nRead more\\n2\\nReply\\n1 reply\\n@KuldeepSingh-fm7bv\\n7 months ago\\nMe watching this just after completing my algo trading bot project . Love from India  really useful videos you make.\\n6\\nReply\\n2 replies\\n@ThePoliticalLambaster1\\n7 months ago\\nThis nonsense that you need to solve a problem. That should be for the skilled developer to do, not a standard programmer. Setting the bar ridiculously high as per usual for standard coders\\n3\\nReply\\n@LeoniiiXD\\n5 months ago\\nFinally a video with cool ideas instead of a how-to-get-hired-101 bunch of lies that infecta the web now\\nReply\\n@dotdotdotdotdash\\n1 month ago\\nUnfair advantage for 181k people is not actually an \"unfair advantage\" anymore\\nReply\\n@ubongudotai\\n1 month ago\\nNice one!\\nReply\\n@vishalpachpande5921\\n5 months ago\\nMy resume filled with computer vision application. Still no response  I will work for free if i can even enter into the market \\nReply\\n1 reply\\n@CygnusX-11\\n3 months ago\\nwhat if everyone decides to stand out and be different\\nReply\\n@martinmugyenyi9437\\n7 months ago\\nAwesome!!! Content.\\nReply\\n@JaisidhSinghBAI\\n6 months ago\\nLast time I was here Tim didn\\'t have a beard. Been a while.\\nReply\\n@McLovinYoMuffin\\n7 months ago\\nBro whats with the dark circles and fatigue around your eyes in your vids?  You eating right and getting enough sleep?  I used to have that, then switched to the carnivore diet and I feel awesome.\\n1\\nReply\\n@aboozarsobboohi827\\n7 months ago\\nThanks\\nReply\\n@radosawprzeslakiewicz5770\\n5 months ago\\nAnd some senior dev in his 30s or 40s rather do not have time for such play ...\\nReply\\n@dunyagg00\\n7 months ago\\nI am just wondering can a 2nd grade build such things  ?\\nReply\\n1 reply\\n@completelyanonymous4519\\n7 months ago\\nEnd up with nobody around. End up with no nodes anywhere....\\nReply\\n@TheCidraque\\n5 months ago\\nDon\\'t be scared man, embrace baldness you are going to look hot\\n1\\nReply\\n路\\n1 reply\\n@Pepcen\\n7 months ago\\nYour titles are so clickbaity man\\n3\\nReply\\n@XxMADAXXFAKAxX\\n6 months ago\\ngames are not easy people, in my opinion game dev is the hardest programming class that you can put your hands on but f* me its hella fun ^^ dont forget the hard part tho\\nReply\\n@DennisPing\\n6 months ago\\nSwole with Tim\\nReply\\n@CurioMotiveClips\\n5 months ago\\ncommenting to make my feed like this\\nReply\\n@completelyanonymous4519\\n7 months ago\\nEnd up with no nodes left\\nReply\\n@yktv_edotty\\n7 months ago\\nI remember you from 2020\\nReply\\n@catguy96\\n4 months ago\\nRecruiter: We are hiring for an entry level junior developer job\\nJob seeker: I just applied for this job. I have over 3 years of experience using React and Angular\\nRecruiter: lmfao thats cute. we\\'re looking for 7+ years of machine learning & SQL experience and 5 professional references who can prove you can do the job\\nJob seeker: no wonder why tech is fucked\\nRecruiter: not my problem\\nRead more\\nReply\\n@completelyanonymous4519\\n7 months ago\\nAre you sure, man? What are you high or something?\\n2\\nReply\\n@charlinamaxwell3595\\n6 months ago\\ntim get a dangly earring\\nReply\\n@sascha1461\\n1 month ago\\nyou can surely get a job in a crypto bro company with that resume lol\\nReply\\n@johndowland4623\\n5 months ago\\nDon\\'t believe all these yt videos on the topic. What they really care is if you\\'re willing to do 8 hours at 15 eur /hr, you\\'re young, and you have no ambitions. If you got it all but don\\'t have a degree in IT they\\'ll pick the one who also got it all included the degree. These have been 100% of the recruiters on linkedin for the last 5 years. They don\\'t even open the fucking link of your projects, don\\'t worry.\\nRead more\\nReply\\n@nihalgamc433\\n6 months ago\\nnow everyone has an unfair advantage...\\nReply\\n路\\n2 replies\\n@yahyaa4499\\n7 months ago\\nFull stack app?\\nReply\\n@completelyanonymous4519\\n7 months ago\\nComputer virus and bacteria everywhere....\\nReply\\n@brandonromero421\\n5 months ago\\nYOU MADE AGARIO????\\nReply\\n路\\n1 reply\\n@completelyanonymous4519\\n7 months ago\\nCopy and virus. Copy Angelou\\'s and copy and copy and copyong and all the data. And greedy people tryong to delete everybody \\nReply\\n@user-cl8ij5hu9h\\n7 months ago\\nthey are not unique anymore \\nReply\\n@_.-.\\n5 months ago\\nWow, these suck!\\nReply\\n路\\n1 reply\\n@PapaMufti\\n7 months ago\\nfirst!\\nReply\\n@completelyanonymous4519\\n7 months ago\\nYou might copy a virus.\\nReply\\n@jamesbondisamonkey\\n7 months ago\\nand by watching and copying this video, now all of the projects here will be shared, until a new video is made, and so forth\\nReply',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_youtube_comments('https://www.youtube.com/watch?v=V1hjSeSF4xg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3402f560-ce48-4c0b-b22a-4601e7523e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcomments\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "595ed184-94ac-4d29-ad94-b01f75f7893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)   # Remove URLs\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))   # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text) # Remove numbers\n",
    "    \n",
    "    text = emoji.demojize(text)  # Remove emojis\n",
    "    text = re.sub(r':[a-z_]+:', '', text)\n",
    "\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    \n",
    "    stop_words = stopwords.words('english')  # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    tokens = [slang_dict.get(token, token) for token in tokens]  # Handle short forms\n",
    "    \n",
    "    # Spelling correction and lemmatization using TextBlob\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        word = Word(token)\n",
    "        corrected_word = word.correct()  # This will handle misspellings like 'gud', 'osm'\n",
    "        lemmatized_word = lemmatizer.lemmatize(str(corrected_word))\n",
    "        corrected_tokens.append(lemmatized_word)\n",
    "\n",
    "    return ' '.join(corrected_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21015c85-645d-4085-a1ba-9bdc401fd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment of text using VADER\"\"\"\n",
    "    # Initialize VADER\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    sentiment_scores = sia.polarity_scores(preprocessed_text)\n",
    "    return sentiment_scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bef901f0-a732-4e6c-bf22-d05b10c6a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comments(url):\n",
    "    \"\"\"Scrape and analyze comments from a YouTube video\"\"\"\n",
    "    # Scrape comments\n",
    "    comments = scrape_youtube_comments(url)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(comments, columns=['comment'])\n",
    "\n",
    "    # Preprocess comments\n",
    "    df['cleaned_comment'] = df['comment'].apply(preprocess_text)\n",
    "\n",
    "    # Analyze sentiment\n",
    "    df['sentiment'] = df['cleaned_comment'].apply(analyze_sentiment)\n",
    "\n",
    "    # Categorize sentiment\n",
    "    df['sentiment_category'] = pd.cut(df['sentiment'], \n",
    "                                      bins=[-1, -0.1, 0.1, 1], \n",
    "                                      labels=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb0ca200-b3e0-410b-b58d-22754232d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinned by Tech With Tim\\n@TechWithTim\\n7 month...</td>\n",
       "      <td>pinned teach tim techwithtim month ago another...</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  \\\n",
       "0   Pinned by Tech With Tim\\n@TechWithTim\\n7 month...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "\n",
       "                                      cleaned_comment  sentiment  \\\n",
       "0   pinned teach tim techwithtim month ago another...     0.9994   \n",
       "1                                                         0.0000   \n",
       "2                                                         0.0000   \n",
       "3                                                         0.0000   \n",
       "4                                                         0.0000   \n",
       "5                                                         0.0000   \n",
       "6                                                         0.0000   \n",
       "7                                                         0.0000   \n",
       "8                                                         0.0000   \n",
       "9                                                         0.0000   \n",
       "10                                                        0.0000   \n",
       "11                                                        0.0000   \n",
       "12                                                        0.0000   \n",
       "13                                                        0.0000   \n",
       "14                                                        0.0000   \n",
       "15                                                        0.0000   \n",
       "16                                                        0.0000   \n",
       "17                                                        0.0000   \n",
       "18                                                        0.0000   \n",
       "19                                                        0.0000   \n",
       "20                                                        0.0000   \n",
       "21                                                        0.0000   \n",
       "22                                                        0.0000   \n",
       "23                                                        0.0000   \n",
       "24                                                        0.0000   \n",
       "25                                                        0.0000   \n",
       "26                                                        0.0000   \n",
       "\n",
       "   sentiment_category  \n",
       "0            Positive  \n",
       "1             Neutral  \n",
       "2             Neutral  \n",
       "3             Neutral  \n",
       "4             Neutral  \n",
       "5             Neutral  \n",
       "6             Neutral  \n",
       "7             Neutral  \n",
       "8             Neutral  \n",
       "9             Neutral  \n",
       "10            Neutral  \n",
       "11            Neutral  \n",
       "12            Neutral  \n",
       "13            Neutral  \n",
       "14            Neutral  \n",
       "15            Neutral  \n",
       "16            Neutral  \n",
       "17            Neutral  \n",
       "18            Neutral  \n",
       "19            Neutral  \n",
       "20            Neutral  \n",
       "21            Neutral  \n",
       "22            Neutral  \n",
       "23            Neutral  \n",
       "24            Neutral  \n",
       "25            Neutral  \n",
       "26            Neutral  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_comments('https://www.youtube.com/watch?v=V1hjSeSF4xg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c55e0e1-cff1-4737-a31d-94f4ac2ed47a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af9cddb-d383-4cbd-a6d9-ab66472c0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(df):\n",
    "    # Word cloud of most common words\n",
    "    text = ' '.join(df['cleaned_comment'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # CleanCache(directory='static')\n",
    "    plt.title('Most Common Words in Comments')\n",
    "    plt.savefig('static/wordcloud.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb501a2-a571-447e-b87f-c9e4453988c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(df):\n",
    "    \"\"\"Generate a summary of the sentiment analysis\"\"\"\n",
    "    total_comments = len(df)\n",
    "    sentiment_counts = df['sentiment_category'].value_counts()\n",
    "    average_sentiment = df['sentiment'].mean()\n",
    "\n",
    "    summary = {\n",
    "        'total_comments': total_comments,\n",
    "        'positive_comments': sentiment_counts.get('Positive', 0),\n",
    "        'neutral_comments': sentiment_counts.get('Neutral', 0),\n",
    "        'negative_comments': sentiment_counts.get('Negative', 0),\n",
    "        'average_sentiment': average_sentiment\n",
    "    }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53afe215-e370-4935-95d3-e2f424286beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function will be called from the Flask app\n",
    "def main(url):\n",
    "    df = analyze_comments(url)\n",
    "    generate_visualizations(df)\n",
    "    summary = get_summary(df)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9fd95f5-7e17-493c-826e-b9a211dfe44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CleanCache:\n",
    "# \t'''\n",
    "# \tthis class is responsible to clear any residual csv and image files\n",
    "# \tpresent due to the past searches made.\n",
    "# \t'''\n",
    "# \tdef __init__(self, directory=None):\n",
    "# \t\tself.clean_path = directory\n",
    "# \t\t# only proceed if directory is not empty\n",
    "# \t\tif os.listdir(self.clean_path) != list():\n",
    "# \t\t\t# iterate over the files and remove each file\n",
    "# \t\t\tfiles = os.listdir(self.clean_path)\n",
    "# \t\t\tfor fileName in files:\n",
    "# \t\t\t\tprint(fileName)\n",
    "# \t\t\t\tos.remove(os.path.join(self.clean_path, fileName))\n",
    "# \t\tprint(\"cleaned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5071df22-6bcf-4107-902b-a1e4d19b6b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_comments': 15, 'positive_comments': 1, 'neutral_comments': 14, 'negative_comments': 0, 'average_sentiment': 0.06644}\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "test_url = \"https://www.youtube.com/watch?v=mWrg19Dc_uY\" \n",
    "result = main(test_url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c13820-1520-4a50-b16a-2d91b4aa6a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dda61-bdb7-4b0a-a2ec-e1ba6a13e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9021a7-c8ee-4167-9a46-51ae076491b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ee035-2e42-4ac8-af61-f13c07b09637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afcbd3-ceee-4701-847d-9cf9cf16784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90ce03-6e7c-4a79-9d3d-afed2f850038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b3406-1521-49fe-b1ca-9acc2e41ea39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332b585-b93c-452a-b007-ac9e2770e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c2e14-e43b-45ef-9891-3584612dc5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2699db6-2145-4c8c-83cf-ccc1b13e6027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb34fb-b3bb-414d-88f5-b9f57282c6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
